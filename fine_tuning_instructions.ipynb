{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92FZ0NS_-anR",
        "outputId": "8ba4355c-ec6a-43cc-caa8-324b0c60994a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tiktoken==0.7.0\n",
            "  Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken==0.7.0) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken==0.7.0) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken==0.7.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken==0.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken==0.7.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken==0.7.0) (2025.1.31)\n",
            "Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken==0.7.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9d8b5j9nHj_z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/Fine-Tuining-Instructions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-1ktqZEH0x8"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "import pandas as pd\n",
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from model import GPTModel\n",
        "from utilities import generate, text_to_ids, ids_to_text\n",
        "from load_gpt2_small_weights import download_and_save, get_new_config, load_weights_into_gpt\n",
        "import json\n",
        "import urllib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WVf5O9otH03E"
      },
      "outputs": [],
      "source": [
        "def download_and_load_file(file_path, url):\n",
        "    if not os.path.exists(file_path):\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            text_data = response.read().decode(\"utf-8\")\n",
        "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "            file.write(text_data)\n",
        "    else:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            text_data = file.read()\n",
        "        with open(file_path, \"r\") as file:\n",
        "            data = json.load(file)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLpi0CVeH05k",
        "outputId": "16569458-5083-4b83-e29b-b37fcf8214d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of entries: 1100\n"
          ]
        }
      ],
      "source": [
        "file_path = \"instruction-data.json\"\n",
        "url = (\n",
        "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
        "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
        "    )\n",
        "data = download_and_load_file(file_path, url)\n",
        "print(\"Number of entries:\", len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0FyU0rCH08A",
        "outputId": "2514f2ec-83eb-43be-a6c2-d4e90292edcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example entry:\n",
            " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
          ]
        }
      ],
      "source": [
        "print(\"Example entry:\\n\", data[50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_5ZyzapH0-k",
        "outputId": "63b69d3d-5971-4a97-fbba-82ce2f99acec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Another example entry:\n",
            " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
          ]
        }
      ],
      "source": [
        "print(\"Another example entry:\\n\", data[999])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_ItBU-usH1BM"
      },
      "outputs": [],
      "source": [
        "def format_input(entry):\n",
        "    instruction_text = (\n",
        "        f\"Below is an instruction that describes a task. \"\n",
        "        f\"Write a response that appropriately completes the request.\"\n",
        "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "    )\n",
        "    input_text = (\n",
        "        f\"\\n\\n### Input:\\n{entry['input']}\" if entry['input'] else \"\"\n",
        "    )\n",
        "    return instruction_text + input_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqRTpZVEH1Dm",
        "outputId": "b8402946-3b3f-4cf1-d5eb-113e1b4d0f2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Identify the correct spelling of the following word.\n",
            "\n",
            "### Input:\n",
            "Ocassion\n",
            "\n",
            "### Response:\n",
            "The correct spelling is 'Occasion.'\n"
          ]
        }
      ],
      "source": [
        "model_input = format_input(data[50])\n",
        "model_output = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
        "\n",
        "print(model_input + model_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iY5m0YF3H1Gc",
        "outputId": "88d4a2c6-7898-4795-fa66-92d6cfd86cd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What is an antonym of 'complicated'?\n",
            "\n",
            "### Response:\n",
            "An antonym of 'complicated' is 'simple'.\n"
          ]
        }
      ],
      "source": [
        "model_input = format_input(data[999])\n",
        "model_output = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
        "\n",
        "print(model_input + model_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsBa1AbwIKZH",
        "outputId": "4db2f956-d19e-4dc9-ed7e-74682526652e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training examples: 935\n",
            "Number of test examples: 110\n",
            "Number of validation examples: 55\n"
          ]
        }
      ],
      "source": [
        "train_portion = int(len(data) * 0.85)\n",
        "test_portion = int(len(data) * 0.1)\n",
        "val_portion = len(data) - train_portion - test_portion\n",
        "\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion:train_portion + test_portion]\n",
        "val_data = data[train_portion + test_portion:]\n",
        "\n",
        "print(\"Number of training examples:\", len(train_data))\n",
        "print(\"Number of test examples:\", len(test_data))\n",
        "print(\"Number of validation examples:\", len(val_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn813M2YIPEn",
        "outputId": "534bf864-afc6-4f6e-89bc-dddb1577d0ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'instruction': 'Evaluate the following phrase by transforming it into the spelling given.', 'input': 'freind --> friend', 'output': 'The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".'}\n",
            "{'instruction': 'Edit the following sentence for grammar.', 'input': 'He go to the park every day.', 'output': 'He goes to the park every day.'}\n",
            "{'instruction': 'Convert 45 kilometers to meters.', 'input': '', 'output': '45 kilometers is 45000 meters.'}\n",
            "{'instruction': \"Rewrite this sentence to start with 'Although': Despite the rain, they went for a walk.\", 'input': '', 'output': 'Although it was raining, they went for a walk.'}\n",
            "{'instruction': 'What are the first 10 square numbers?', 'input': '', 'output': '1, 4, 9, 16, 25, 36, 49, 64, 81, 100.'}\n"
          ]
        }
      ],
      "source": [
        "for entry in train_data[:5]:\n",
        "    print(entry)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jb70QDBmIQV0"
      },
      "outputs": [],
      "source": [
        "class InstructionDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "        self.encoded_texts = []\n",
        "        for entry in data:\n",
        "            instruction_input = format_input(entry)\n",
        "            response_output = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
        "            full_text = instruction_input + response_output\n",
        "            self.encoded_texts.append(tokenizer.encode(full_text))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.encoded_texts[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-rMmLkCIRmn",
        "outputId": "8e25a349-e427-44f2-de81-bdc7c4b27893"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[50256]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "pad_token_id = tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"})\n",
        "print(pad_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA8kIK6tISsD",
        "outputId": "288a3b9f-7225-4de2-db42-ea21a55ff09f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'instruction': 'Evaluate the following phrase by transforming it into the spelling given.',\n",
              " 'input': 'freind --> friend',\n",
              " 'output': 'The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".'}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4RgN0JSIT5I",
        "outputId": "a3846078-51bd-4b24-a0a0-3a406a38b3f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "935\n",
            "[21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 19430, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 198, 198, 21017, 46486, 25, 198, 36, 2100, 4985, 262, 1708, 9546, 416, 25449, 340, 656, 262, 24993, 1813, 13, 198, 198, 21017, 23412, 25, 198, 19503, 521, 14610, 1545, 198, 198, 21017, 18261, 25, 198, 464, 24993, 286, 262, 1813, 9546, 366, 19503, 521, 1, 318, 11491, 11, 262, 3376, 24993, 318, 366, 6726, 1911]\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Evaluate the following phrase by transforming it into the spelling given.\n",
            "\n",
            "### Input:\n",
            "freind --> friend\n",
            "\n",
            "### Response:\n",
            "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".\n"
          ]
        }
      ],
      "source": [
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "print(len(train_dataset))\n",
        "print(train_dataset[0])\n",
        "print(tokenizer.decode(train_dataset[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Q0pt8TYcIVdF"
      },
      "outputs": [],
      "source": [
        "def custom_collate_fn(batch, pad_token_id, device=\"cpu\", ignore_index = -100, allowed_max_len = None):\n",
        "    max_len_of_batch = max(len(item) for item in batch)\n",
        "    input_lst, target_lst = [], []\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        padded = (new_item + pad_token_id * (max_len_of_batch - len(new_item)))\n",
        "        inputs = torch.tensor(padded)\n",
        "        target = torch.tensor(padded[1:] + pad_token_id)\n",
        "        mask = target == pad_token_id[0]\n",
        "        indices = torch.nonzero(mask).squeeze()\n",
        "        if indices.numel() > 1:\n",
        "            target[indices[1:]] = ignore_index\n",
        "\n",
        "        if allowed_max_len is not None:\n",
        "            inputs = inputs[:allowed_max_len]\n",
        "            target = target[:allowed_max_len]\n",
        "\n",
        "        input_lst.append(inputs)\n",
        "        target_lst.append(target)\n",
        "    input_tensor = torch.stack(input_lst).to(device)\n",
        "    target_tensor = torch.stack(target_lst).to(device)\n",
        "    return input_tensor, target_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH1s1xWFIXj0",
        "outputId": "45686e38-8446-4a00-d0f3-77e13f810c7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rCpoYsn3IaeJ"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "customized_collate_fn = partial(\n",
        "    custom_collate_fn,\n",
        "    device=device,\n",
        "    pad_token_id=pad_token_id,\n",
        "    ignore_index=-100,\n",
        "    allowed_max_len=1024\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7vCSAx7SIboE"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers,\n",
        "    collate_fn=customized_collate_fn,\n",
        ")\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers,\n",
        "    collate_fn=customized_collate_fn,\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers,\n",
        "    collate_fn=customized_collate_fn,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7L1wMpQbIdAa",
        "outputId": "4b64b4e6-a13b-4e7d-ae62-aba45eab375b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 0\n",
            "Input tensor shape: torch.Size([8, 61])\n",
            "Target tensor shape: torch.Size([8, 61])\n",
            "Batch 1\n",
            "Input tensor shape: torch.Size([8, 76])\n",
            "Target tensor shape: torch.Size([8, 76])\n",
            "Batch 2\n",
            "Input tensor shape: torch.Size([8, 73])\n",
            "Target tensor shape: torch.Size([8, 73])\n",
            "Batch 3\n",
            "Input tensor shape: torch.Size([8, 68])\n",
            "Target tensor shape: torch.Size([8, 68])\n",
            "Batch 4\n",
            "Input tensor shape: torch.Size([8, 65])\n",
            "Target tensor shape: torch.Size([8, 65])\n",
            "Batch 5\n",
            "Input tensor shape: torch.Size([8, 72])\n",
            "Target tensor shape: torch.Size([8, 72])\n",
            "Batch 6\n",
            "Input tensor shape: torch.Size([8, 80])\n",
            "Target tensor shape: torch.Size([8, 80])\n",
            "Batch 7\n",
            "Input tensor shape: torch.Size([8, 67])\n",
            "Target tensor shape: torch.Size([8, 67])\n",
            "Batch 8\n",
            "Input tensor shape: torch.Size([8, 62])\n",
            "Target tensor shape: torch.Size([8, 62])\n",
            "Batch 9\n",
            "Input tensor shape: torch.Size([8, 75])\n",
            "Target tensor shape: torch.Size([8, 75])\n",
            "Batch 10\n",
            "Input tensor shape: torch.Size([8, 62])\n",
            "Target tensor shape: torch.Size([8, 62])\n",
            "Batch 11\n",
            "Input tensor shape: torch.Size([8, 68])\n",
            "Target tensor shape: torch.Size([8, 68])\n",
            "Batch 12\n",
            "Input tensor shape: torch.Size([8, 67])\n",
            "Target tensor shape: torch.Size([8, 67])\n",
            "Batch 13\n",
            "Input tensor shape: torch.Size([8, 77])\n",
            "Target tensor shape: torch.Size([8, 77])\n",
            "Batch 14\n",
            "Input tensor shape: torch.Size([8, 69])\n",
            "Target tensor shape: torch.Size([8, 69])\n",
            "Batch 15\n",
            "Input tensor shape: torch.Size([8, 79])\n",
            "Target tensor shape: torch.Size([8, 79])\n",
            "Batch 16\n",
            "Input tensor shape: torch.Size([8, 71])\n",
            "Target tensor shape: torch.Size([8, 71])\n",
            "Batch 17\n",
            "Input tensor shape: torch.Size([8, 66])\n",
            "Target tensor shape: torch.Size([8, 66])\n",
            "Batch 18\n",
            "Input tensor shape: torch.Size([8, 83])\n",
            "Target tensor shape: torch.Size([8, 83])\n",
            "Batch 19\n",
            "Input tensor shape: torch.Size([8, 68])\n",
            "Target tensor shape: torch.Size([8, 68])\n",
            "Batch 20\n",
            "Input tensor shape: torch.Size([8, 80])\n",
            "Target tensor shape: torch.Size([8, 80])\n",
            "Batch 21\n",
            "Input tensor shape: torch.Size([8, 71])\n",
            "Target tensor shape: torch.Size([8, 71])\n",
            "Batch 22\n",
            "Input tensor shape: torch.Size([8, 69])\n",
            "Target tensor shape: torch.Size([8, 69])\n",
            "Batch 23\n",
            "Input tensor shape: torch.Size([8, 65])\n",
            "Target tensor shape: torch.Size([8, 65])\n",
            "Batch 24\n",
            "Input tensor shape: torch.Size([8, 68])\n",
            "Target tensor shape: torch.Size([8, 68])\n",
            "Batch 25\n",
            "Input tensor shape: torch.Size([8, 60])\n",
            "Target tensor shape: torch.Size([8, 60])\n",
            "Batch 26\n",
            "Input tensor shape: torch.Size([8, 59])\n",
            "Target tensor shape: torch.Size([8, 59])\n",
            "Batch 27\n",
            "Input tensor shape: torch.Size([8, 69])\n",
            "Target tensor shape: torch.Size([8, 69])\n",
            "Batch 28\n",
            "Input tensor shape: torch.Size([8, 63])\n",
            "Target tensor shape: torch.Size([8, 63])\n",
            "Batch 29\n",
            "Input tensor shape: torch.Size([8, 65])\n",
            "Target tensor shape: torch.Size([8, 65])\n",
            "Batch 30\n",
            "Input tensor shape: torch.Size([8, 76])\n",
            "Target tensor shape: torch.Size([8, 76])\n",
            "Batch 31\n",
            "Input tensor shape: torch.Size([8, 66])\n",
            "Target tensor shape: torch.Size([8, 66])\n",
            "Batch 32\n",
            "Input tensor shape: torch.Size([8, 71])\n",
            "Target tensor shape: torch.Size([8, 71])\n",
            "Batch 33\n",
            "Input tensor shape: torch.Size([8, 91])\n",
            "Target tensor shape: torch.Size([8, 91])\n",
            "Batch 34\n",
            "Input tensor shape: torch.Size([8, 65])\n",
            "Target tensor shape: torch.Size([8, 65])\n",
            "Batch 35\n",
            "Input tensor shape: torch.Size([8, 64])\n",
            "Target tensor shape: torch.Size([8, 64])\n",
            "Batch 36\n",
            "Input tensor shape: torch.Size([8, 67])\n",
            "Target tensor shape: torch.Size([8, 67])\n",
            "Batch 37\n",
            "Input tensor shape: torch.Size([8, 66])\n",
            "Target tensor shape: torch.Size([8, 66])\n",
            "Batch 38\n",
            "Input tensor shape: torch.Size([8, 64])\n",
            "Target tensor shape: torch.Size([8, 64])\n",
            "Batch 39\n",
            "Input tensor shape: torch.Size([8, 65])\n",
            "Target tensor shape: torch.Size([8, 65])\n",
            "Batch 40\n",
            "Input tensor shape: torch.Size([8, 75])\n",
            "Target tensor shape: torch.Size([8, 75])\n",
            "Batch 41\n",
            "Input tensor shape: torch.Size([8, 89])\n",
            "Target tensor shape: torch.Size([8, 89])\n",
            "Batch 42\n",
            "Input tensor shape: torch.Size([8, 59])\n",
            "Target tensor shape: torch.Size([8, 59])\n",
            "Batch 43\n",
            "Input tensor shape: torch.Size([8, 88])\n",
            "Target tensor shape: torch.Size([8, 88])\n",
            "Batch 44\n",
            "Input tensor shape: torch.Size([8, 83])\n",
            "Target tensor shape: torch.Size([8, 83])\n",
            "Batch 45\n",
            "Input tensor shape: torch.Size([8, 83])\n",
            "Target tensor shape: torch.Size([8, 83])\n",
            "Batch 46\n",
            "Input tensor shape: torch.Size([8, 70])\n",
            "Target tensor shape: torch.Size([8, 70])\n",
            "Batch 47\n",
            "Input tensor shape: torch.Size([8, 65])\n",
            "Target tensor shape: torch.Size([8, 65])\n",
            "Batch 48\n",
            "Input tensor shape: torch.Size([8, 74])\n",
            "Target tensor shape: torch.Size([8, 74])\n",
            "Batch 49\n",
            "Input tensor shape: torch.Size([8, 76])\n",
            "Target tensor shape: torch.Size([8, 76])\n",
            "Batch 50\n",
            "Input tensor shape: torch.Size([8, 67])\n",
            "Target tensor shape: torch.Size([8, 67])\n",
            "Batch 51\n",
            "Input tensor shape: torch.Size([8, 75])\n",
            "Target tensor shape: torch.Size([8, 75])\n",
            "Batch 52\n",
            "Input tensor shape: torch.Size([8, 83])\n",
            "Target tensor shape: torch.Size([8, 83])\n",
            "Batch 53\n",
            "Input tensor shape: torch.Size([8, 69])\n",
            "Target tensor shape: torch.Size([8, 69])\n",
            "Batch 54\n",
            "Input tensor shape: torch.Size([8, 67])\n",
            "Target tensor shape: torch.Size([8, 67])\n",
            "Batch 55\n",
            "Input tensor shape: torch.Size([8, 60])\n",
            "Target tensor shape: torch.Size([8, 60])\n",
            "Batch 56\n",
            "Input tensor shape: torch.Size([8, 60])\n",
            "Target tensor shape: torch.Size([8, 60])\n",
            "Batch 57\n",
            "Input tensor shape: torch.Size([8, 66])\n",
            "Target tensor shape: torch.Size([8, 66])\n",
            "Batch 58\n",
            "Input tensor shape: torch.Size([8, 80])\n",
            "Target tensor shape: torch.Size([8, 80])\n",
            "Batch 59\n",
            "Input tensor shape: torch.Size([8, 71])\n",
            "Target tensor shape: torch.Size([8, 71])\n",
            "Batch 60\n",
            "Input tensor shape: torch.Size([8, 61])\n",
            "Target tensor shape: torch.Size([8, 61])\n",
            "Batch 61\n",
            "Input tensor shape: torch.Size([8, 58])\n",
            "Target tensor shape: torch.Size([8, 58])\n",
            "Batch 62\n",
            "Input tensor shape: torch.Size([8, 71])\n",
            "Target tensor shape: torch.Size([8, 71])\n",
            "Batch 63\n",
            "Input tensor shape: torch.Size([8, 67])\n",
            "Target tensor shape: torch.Size([8, 67])\n",
            "Batch 64\n",
            "Input tensor shape: torch.Size([8, 68])\n",
            "Target tensor shape: torch.Size([8, 68])\n",
            "Batch 65\n",
            "Input tensor shape: torch.Size([8, 63])\n",
            "Target tensor shape: torch.Size([8, 63])\n",
            "Batch 66\n",
            "Input tensor shape: torch.Size([8, 87])\n",
            "Target tensor shape: torch.Size([8, 87])\n",
            "Batch 67\n",
            "Input tensor shape: torch.Size([8, 68])\n",
            "Target tensor shape: torch.Size([8, 68])\n",
            "Batch 68\n",
            "Input tensor shape: torch.Size([8, 64])\n",
            "Target tensor shape: torch.Size([8, 64])\n",
            "Batch 69\n",
            "Input tensor shape: torch.Size([8, 68])\n",
            "Target tensor shape: torch.Size([8, 68])\n",
            "Batch 70\n",
            "Input tensor shape: torch.Size([8, 71])\n",
            "Target tensor shape: torch.Size([8, 71])\n",
            "Batch 71\n",
            "Input tensor shape: torch.Size([8, 68])\n",
            "Target tensor shape: torch.Size([8, 68])\n",
            "Batch 72\n",
            "Input tensor shape: torch.Size([8, 71])\n",
            "Target tensor shape: torch.Size([8, 71])\n",
            "Batch 73\n",
            "Input tensor shape: torch.Size([8, 61])\n",
            "Target tensor shape: torch.Size([8, 61])\n",
            "Batch 74\n",
            "Input tensor shape: torch.Size([8, 65])\n",
            "Target tensor shape: torch.Size([8, 65])\n",
            "Batch 75\n",
            "Input tensor shape: torch.Size([8, 67])\n",
            "Target tensor shape: torch.Size([8, 67])\n",
            "Batch 76\n",
            "Input tensor shape: torch.Size([8, 65])\n",
            "Target tensor shape: torch.Size([8, 65])\n",
            "Batch 77\n",
            "Input tensor shape: torch.Size([8, 64])\n",
            "Target tensor shape: torch.Size([8, 64])\n",
            "Batch 78\n",
            "Input tensor shape: torch.Size([8, 60])\n",
            "Target tensor shape: torch.Size([8, 60])\n",
            "Batch 79\n",
            "Input tensor shape: torch.Size([8, 72])\n",
            "Target tensor shape: torch.Size([8, 72])\n",
            "Batch 80\n",
            "Input tensor shape: torch.Size([8, 64])\n",
            "Target tensor shape: torch.Size([8, 64])\n",
            "Batch 81\n",
            "Input tensor shape: torch.Size([8, 70])\n",
            "Target tensor shape: torch.Size([8, 70])\n",
            "Batch 82\n",
            "Input tensor shape: torch.Size([8, 57])\n",
            "Target tensor shape: torch.Size([8, 57])\n",
            "Batch 83\n",
            "Input tensor shape: torch.Size([8, 72])\n",
            "Target tensor shape: torch.Size([8, 72])\n",
            "Batch 84\n",
            "Input tensor shape: torch.Size([8, 64])\n",
            "Target tensor shape: torch.Size([8, 64])\n",
            "Batch 85\n",
            "Input tensor shape: torch.Size([8, 68])\n",
            "Target tensor shape: torch.Size([8, 68])\n",
            "Batch 86\n",
            "Input tensor shape: torch.Size([8, 62])\n",
            "Target tensor shape: torch.Size([8, 62])\n",
            "Batch 87\n",
            "Input tensor shape: torch.Size([8, 74])\n",
            "Target tensor shape: torch.Size([8, 74])\n",
            "Batch 88\n",
            "Input tensor shape: torch.Size([8, 80])\n",
            "Target tensor shape: torch.Size([8, 80])\n",
            "Batch 89\n",
            "Input tensor shape: torch.Size([8, 68])\n",
            "Target tensor shape: torch.Size([8, 68])\n",
            "Batch 90\n",
            "Input tensor shape: torch.Size([8, 70])\n",
            "Target tensor shape: torch.Size([8, 70])\n",
            "Batch 91\n",
            "Input tensor shape: torch.Size([8, 91])\n",
            "Target tensor shape: torch.Size([8, 91])\n",
            "Batch 92\n",
            "Input tensor shape: torch.Size([8, 61])\n",
            "Target tensor shape: torch.Size([8, 61])\n",
            "Batch 93\n",
            "Input tensor shape: torch.Size([8, 66])\n",
            "Target tensor shape: torch.Size([8, 66])\n",
            "Batch 94\n",
            "Input tensor shape: torch.Size([8, 80])\n",
            "Target tensor shape: torch.Size([8, 80])\n",
            "Batch 95\n",
            "Input tensor shape: torch.Size([8, 81])\n",
            "Target tensor shape: torch.Size([8, 81])\n",
            "Batch 96\n",
            "Input tensor shape: torch.Size([8, 74])\n",
            "Target tensor shape: torch.Size([8, 74])\n",
            "Batch 97\n",
            "Input tensor shape: torch.Size([8, 82])\n",
            "Target tensor shape: torch.Size([8, 82])\n",
            "Batch 98\n",
            "Input tensor shape: torch.Size([8, 63])\n",
            "Target tensor shape: torch.Size([8, 63])\n",
            "Batch 99\n",
            "Input tensor shape: torch.Size([8, 83])\n",
            "Target tensor shape: torch.Size([8, 83])\n",
            "Batch 100\n",
            "Input tensor shape: torch.Size([8, 68])\n",
            "Target tensor shape: torch.Size([8, 68])\n",
            "Batch 101\n",
            "Input tensor shape: torch.Size([8, 67])\n",
            "Target tensor shape: torch.Size([8, 67])\n",
            "Batch 102\n",
            "Input tensor shape: torch.Size([8, 77])\n",
            "Target tensor shape: torch.Size([8, 77])\n",
            "Batch 103\n",
            "Input tensor shape: torch.Size([8, 91])\n",
            "Target tensor shape: torch.Size([8, 91])\n",
            "Batch 104\n",
            "Input tensor shape: torch.Size([8, 64])\n",
            "Target tensor shape: torch.Size([8, 64])\n",
            "Batch 105\n",
            "Input tensor shape: torch.Size([8, 61])\n",
            "Target tensor shape: torch.Size([8, 61])\n",
            "Batch 106\n",
            "Input tensor shape: torch.Size([8, 75])\n",
            "Target tensor shape: torch.Size([8, 75])\n",
            "Batch 107\n",
            "Input tensor shape: torch.Size([8, 64])\n",
            "Target tensor shape: torch.Size([8, 64])\n",
            "Batch 108\n",
            "Input tensor shape: torch.Size([8, 66])\n",
            "Target tensor shape: torch.Size([8, 66])\n",
            "Batch 109\n",
            "Input tensor shape: torch.Size([8, 78])\n",
            "Target tensor shape: torch.Size([8, 78])\n",
            "Batch 110\n",
            "Input tensor shape: torch.Size([8, 66])\n",
            "Target tensor shape: torch.Size([8, 66])\n",
            "Batch 111\n",
            "Input tensor shape: torch.Size([8, 64])\n",
            "Target tensor shape: torch.Size([8, 64])\n",
            "Batch 112\n",
            "Input tensor shape: torch.Size([8, 83])\n",
            "Target tensor shape: torch.Size([8, 83])\n",
            "Batch 113\n",
            "Input tensor shape: torch.Size([8, 66])\n",
            "Target tensor shape: torch.Size([8, 66])\n",
            "Batch 114\n",
            "Input tensor shape: torch.Size([8, 74])\n",
            "Target tensor shape: torch.Size([8, 74])\n",
            "Batch 115\n",
            "Input tensor shape: torch.Size([8, 69])\n",
            "Target tensor shape: torch.Size([8, 69])\n"
          ]
        }
      ],
      "source": [
        "for i, (input_tensor, target_tensor) in enumerate(train_dataloader):\n",
        "    print(\"Batch\", i)\n",
        "    print(\"Input tensor shape:\", input_tensor.shape)\n",
        "    print(\"Target tensor shape:\", target_tensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Foiqzji5IeTV"
      },
      "outputs": [],
      "source": [
        "from gpt_download import download_and_load_gpt2\n",
        "from model import GPTModel\n",
        "from load_gpt2_small_weights import load_weights_into_gpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "NeQSrF8dIgHb"
      },
      "outputs": [],
      "source": [
        "BASE_CONFIG = {\n",
        " \"vocab_size\": 50257, # Vocabulary size\n",
        " \"context_length\": 1024, # Context length\n",
        " \"drop_rate\": 0.0, # Dropout rate\n",
        " \"qkv_bias\": True # Query-key-value bias\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "R-RZiSwmIhR3"
      },
      "outputs": [],
      "source": [
        "model_configs = {\n",
        " \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        " \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        " \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        " \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu2jaZkdIiXm",
        "outputId": "dfaeaa7a-b6a2-4516-dd83-a0c07e28948f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model configuration: {'vocab_size': 50257, 'context_length': 1024, 'drop_rate': 0.0, 'qkv_bias': True, 'emb_dim': 1024, 'n_layers': 24, 'n_heads': 16}\n"
          ]
        }
      ],
      "source": [
        "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "print(\"Model configuration:\", BASE_CONFIG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_pltmeDIjni",
        "outputId": "485842cd-e727-41f7-e705-71e0b79f3b3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model size: 355M\n"
          ]
        }
      ],
      "source": [
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "print(\"Model size:\", model_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DivF4ttImCY",
        "outputId": "3cab0804-badd-49ff-e3ae-6aa14d94a9d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/355M/checkpoint\n",
            "File already exists and is up-to-date: gpt2/355M/encoder.json\n",
            "File already exists and is up-to-date: gpt2/355M/hparams.json\n",
            "File already exists and is up-to-date: gpt2/355M/model.ckpt.data-00000-of-00001\n",
            "File already exists and is up-to-date: gpt2/355M/model.ckpt.index\n",
            "File already exists and is up-to-date: gpt2/355M/model.ckpt.meta\n",
            "File already exists and is up-to-date: gpt2/355M/vocab.bpe\n"
          ]
        }
      ],
      "source": [
        "settings, params = download_and_load_gpt2(\n",
        " model_size=model_size,\n",
        " models_dir=\"gpt2\"\n",
        ")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jm8SEsqeJBSe",
        "outputId": "7822a943-c725-45c6-a1a9-7bd4e1692c45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (token_embedding): Embedding(50257, 1024)\n",
              "  (position_embedding): Embedding(1024, 1024)\n",
              "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
              "  (blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (w_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_o): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (w_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_o): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (w_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_o): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (w_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_o): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (w_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_o): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (w_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_o): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (w_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_o): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (w_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_o): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (w_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_o): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (w_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_o): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (w_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_o): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (w_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_o): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (12): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (w_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_o): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (13): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (w_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_o): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (14): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (w_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_o): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (15): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (w_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_o): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (16): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (w_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_o): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (17): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (w_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_o): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (18): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (w_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_o): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (19): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (w_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_o): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (20): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (w_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_o): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (21): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (w_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_o): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (22): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (w_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_o): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (23): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (w_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (w_o): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYqYdRY6JNmj",
        "outputId": "6aa12cb4-7ce4-44e1-e49b-1de8e6ea937b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "input_text = format_input(val_data[0])\n",
        "print(input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "6u3RW0wLJNo5"
      },
      "outputs": [],
      "source": [
        "from utilities import generate, text_to_ids, ids_to_text\n",
        "token_ids = generate(\n",
        " model=model,\n",
        " idx=text_to_ids(input_text, tokenizer),\n",
        " max_new_tokens=35,\n",
        " context_size=BASE_CONFIG[\"context_length\"],\n",
        " eos_id=50256,\n",
        ")\n",
        "generated_text = ids_to_text(token_ids, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chZosEmyJNrQ",
        "outputId": "f37d20c2-ef18-4ef9-e867-f6135656cace"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
            "\n",
            "### Response:\n",
            "\n",
            "The chef cooks the meal every day.\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "Convert the active sentence to passive: 'The chef cooks the\n"
          ]
        }
      ],
      "source": [
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xJAdidFJNtn",
        "outputId": "dc2d4caa-81f3-4e8c-ed82-b802bd6206d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Response:\n",
            "\n",
            "The chef cooks the meal every day.\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "Convert the active sentence to passive: 'The chef cooks the\n"
          ]
        }
      ],
      "source": [
        "response_text = generated_text[len(input_text):].strip()\n",
        "print(response_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "aQrWAEfFJTvB"
      },
      "outputs": [],
      "source": [
        "from utilities import calc_loss_loader\n",
        "from train import train_model_simple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5R5eTWKJTxl",
        "outputId": "42c40a8f-e739-4128-c582-12a193300eb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss: 3.825909471511841\n",
            "Validation loss: 3.761934232711792\n"
          ]
        }
      ],
      "source": [
        "model.to(device)\n",
        "torch.manual_seed(123)\n",
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_dataloader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_dataloader, model, device, num_batches=5)\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2D_MNhTJT0I",
        "outputId": "1f9e20f4-713a-4fba-c880-a22d4fd337b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
            "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.103\n",
            "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.944\n",
            "Ep 1 (Step 000015): Train loss 0.857, Val loss 0.906\n",
            "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
            "Ep 1 (Step 000025): Train loss 0.754, Val loss 0.859\n",
            "Ep 1 (Step 000030): Train loss 0.799, Val loss 0.836\n",
            "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.808\n",
            "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
            "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.789\n",
            "Ep 1 (Step 000050): Train loss 0.663, Val loss 0.783\n",
            "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.763\n",
            "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
            "Ep 1 (Step 000065): Train loss 0.653, Val loss 0.735\n",
            "Ep 1 (Step 000070): Train loss 0.533, Val loss 0.729\n",
            "Ep 1 (Step 000075): Train loss 0.568, Val loss 0.729\n",
            "Ep 1 (Step 000080): Train loss 0.604, Val loss 0.725\n",
            "Ep 1 (Step 000085): Train loss 0.509, Val loss 0.710\n",
            "Ep 1 (Step 000090): Train loss 0.563, Val loss 0.691\n",
            "Ep 1 (Step 000095): Train loss 0.502, Val loss 0.681\n",
            "Ep 1 (Step 000100): Train loss 0.504, Val loss 0.677\n",
            "Ep 1 (Step 000105): Train loss 0.565, Val loss 0.670\n",
            "Ep 1 (Step 000110): Train loss 0.554, Val loss 0.666\n",
            "Ep 1 (Step 000115): Train loss 0.508, Val loss 0.663\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meals the chef prepares each day are cooked by his colleague.<|endoftext|>You have asked a question that contains redundant information. What is an antonym of 'solar?'<|endoftext|>The next step for the government should adopt\n",
            "Ep 2 (Step 000120): Train loss 0.435, Val loss 0.671\n",
            "Ep 2 (Step 000125): Train loss 0.451, Val loss 0.687\n",
            "Ep 2 (Step 000130): Train loss 0.447, Val loss 0.682\n",
            "Ep 2 (Step 000135): Train loss 0.405, Val loss 0.681\n",
            "Ep 2 (Step 000140): Train loss 0.410, Val loss 0.681\n",
            "Ep 2 (Step 000145): Train loss 0.369, Val loss 0.681\n",
            "Ep 2 (Step 000150): Train loss 0.382, Val loss 0.675\n",
            "Ep 2 (Step 000155): Train loss 0.414, Val loss 0.675\n",
            "Ep 2 (Step 000160): Train loss 0.412, Val loss 0.684\n",
            "Ep 2 (Step 000165): Train loss 0.379, Val loss 0.686\n",
            "Ep 2 (Step 000170): Train loss 0.322, Val loss 0.680\n",
            "Ep 2 (Step 000175): Train loss 0.338, Val loss 0.667\n",
            "Ep 2 (Step 000180): Train loss 0.392, Val loss 0.656\n",
            "Ep 2 (Step 000185): Train loss 0.415, Val loss 0.657\n",
            "Ep 2 (Step 000190): Train loss 0.340, Val loss 0.648\n",
            "Ep 2 (Step 000195): Train loss 0.328, Val loss 0.633\n",
            "Ep 2 (Step 000200): Train loss 0.309, Val loss 0.633\n",
            "Ep 2 (Step 000205): Train loss 0.353, Val loss 0.631\n",
            "Ep 2 (Step 000210): Train loss 0.364, Val loss 0.630\n",
            "Ep 2 (Step 000215): Train loss 0.394, Val loss 0.634\n",
            "Ep 2 (Step 000220): Train loss 0.297, Val loss 0.644\n",
            "Ep 2 (Step 000225): Train loss 0.342, Val loss 0.658\n",
            "Ep 2 (Step 000230): Train loss 0.294, Val loss 0.657\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: It is the daily ritual of the restaurant.<|endoftext|>Please help improve this article's grammar. It can be helpful to have a more formal sentence.  You need help understanding this information.   \"You have no\n",
            "Training completed in 3.16 minutes.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "torch.manual_seed(123)\n",
        "optimizer = torch.optim.AdamW(\n",
        " model.parameters(), lr=0.00005, weight_decay=0.1\n",
        ")\n",
        "num_epochs = 2\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        " model, train_dataloader, val_dataloader, optimizer, device,\n",
        " num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        " start_context=format_input(val_data[0]), tokenizer=tokenizer )\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "qRC_lUolN_SZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_values(\n",
        "    epochs_seen, examples_seen, train_values, val_values,\n",
        "    label=\"loss\"):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
        "    ax1.plot(\n",
        "    epochs_seen, val_values, linestyle=\"-.\",\n",
        "    label=f\"Validation {label}\"\n",
        "    )\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(label.capitalize())\n",
        "    ax1.legend()\n",
        "\n",
        "    ax2 = ax1.twiny()\n",
        "    ax2.plot(examples_seen, train_values, alpha=0)\n",
        "    ax2.set_xlabel(\"Examples seen\")\n",
        "    fig.tight_layout()\n",
        "    plt.savefig(f\"{label}-plot.pdf\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "YZgAR1z6N_Uz",
        "outputId": "7088f012-0188-454f-9166-9b04af7b147b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_values(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2In4jgtDN_Xb",
        "outputId": "b01bdeb9-8dd7-446b-fafe-1ad081eecd3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Rewrite the sentence using a simile.\n",
            "\n",
            "### Input:\n",
            "The car is very fast.\n",
            "\n",
            "Correct response:\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "Model response:\n",
            ">> The car is as fast as a bullet.\n",
            "-----------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What type of cloud is typically associated with thunderstorms?\n",
            "\n",
            "Correct response:\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "Model response:\n",
            ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
            "-----------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Name the author of 'Pride and Prejudice'.\n",
            "\n",
            "Correct response:\n",
            ">> Jane Austen.\n",
            "\n",
            "Model response:\n",
            ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
            "-----------------------------\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "for entry in test_data[:3]:\n",
        "    input_text = format_input(entry)\n",
        "    token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_ids(input_text, tokenizer).to(device),\n",
        "    max_new_tokens=256,\n",
        "    context_size=BASE_CONFIG[\"context_length\"],\n",
        "    eos_id=50256\n",
        "    )\n",
        "    generated_text = ids_to_text(token_ids, tokenizer)\n",
        "\n",
        "    response_text = (\n",
        "    generated_text[len(input_text):]\n",
        "    .replace(\"### Response:\", \"\")\n",
        "    .strip()\n",
        "    )\n",
        "    print(input_text)\n",
        "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
        "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
        "    print(\"-----------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRNz9v9zN_Zx",
        "outputId": "2c731a33-6c9a-4ce7-c032-6360c811ea05"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 110/110 [01:16<00:00,  1.45it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
        "    input_text = format_input(entry)\n",
        "    token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_ids(input_text, tokenizer).to(device),\n",
        "    max_new_tokens=256,\n",
        "    context_size=BASE_CONFIG[\"context_length\"],\n",
        "    eos_id=50256\n",
        "    )\n",
        "    generated_text = ids_to_text(token_ids, tokenizer)\n",
        "\n",
        "    response_text = (\n",
        "    generated_text[len(input_text):]\n",
        "    .replace(\"### Response:\", \"\")\n",
        "    .strip()\n",
        "    )\n",
        "    test_data[i][\"model_response\"] = response_text\n",
        "    with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
        "        json.dump(test_data, file, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF7jaKltOGAt",
        "outputId": "4951bcb2-7899-442f-b039-677e1bb2c668"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a bullet.'}\n"
          ]
        }
      ],
      "source": [
        "print(test_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMctoqwKOIFH",
        "outputId": "dc2d5e30-06b1-4e2b-843a-59a6336b812b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved as gpt2-medium355M-sft.pth\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
        "torch.save(model.state_dict(), file_name)\n",
        "print(f\"Model saved as {file_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCDduShLQg1y"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
